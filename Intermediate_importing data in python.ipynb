{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86ad9ce",
   "metadata": {},
   "source": [
    "# Importing flat files from the web\n",
    "\n",
    "    learned alredy- flat files such as .txt and .csv\n",
    "    pickled files, excel spredsheets and many more!\n",
    "    \n",
    "    \n",
    "    Learning outcomes- reproducability of Dataset to save time! (like downloading thousands of files from the internet with the help of coding.\n",
    "    making HTTP requests (GET requests) - getting data from the web\n",
    "    scrape web data such as HTML\n",
    "    pass HTML into useful data (BeautifulSoup) \n",
    "    \n",
    "    \n",
    "        Will learn to make use of urllib and request packages \n",
    "        \n",
    "        urlopenI()- accepts URLs instead of file names. \n",
    "    \n",
    " \n",
    "# Automating file download in Python\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve \n",
    "\n",
    "url = provide ip address\n",
    "urlretrieve (url, 'Filename.csv') \n",
    "\n",
    "\n",
    "# Importing flat files from the web: your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from machine learning repository- university of california davis\n",
    "\n",
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')             #file is saved in the name of winequality-red.csv\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55999445",
   "metadata": {},
   "source": [
    "# now, we are going to import the files directly without actually saving it in the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "\n",
    "#Before this, there was a step called urlretrieve to save files in the desired name. The step was missed by me. \n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep= ';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00543e",
   "metadata": {},
   "source": [
    "# Importing non-flat (such as excel) files from the web\n",
    "\n",
    "    we will use pd.read_excel() to import an excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url= 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "\n",
    "# Read in all sheets of Excel file: xls\n",
    "xls= pd.read_excel(url, sheet_name = None)\n",
    "\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print (xls.keys())           \n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print (xls['1700'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3aa9a8",
   "metadata": {},
   "source": [
    "# HTPP requests to import files from the web\n",
    "\n",
    "    URL = uniform/universal resource locator\n",
    "    HTTP = hyper text transfer protocol\n",
    "    going to a website = sending HTTP request (GET request) \n",
    "    urlretrieve() performs the GET request\n",
    "    html= hyper text markup language\n",
    "    \n",
    "    \n",
    "# how to store GET data in the enivronment\n",
    "# example of storing HTML data from wikipedia homepage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "request = Request(url)\n",
    "response = urlopen (request)\n",
    "html = response.read()\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "r= requests.get(url)\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b720de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print (html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45735d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html       \n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print(html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()\n",
    "\n",
    "# en gros!  #package the request, send it, and extract it. Finally, print the html!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e62332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = 'http://www.datacamp.com/teach/documentation'\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r= requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text= r.text                       #using text attribute of the object r. So, no round brackets after\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the web in Python\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "ulr = 'RR'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9897ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods of BeautifulSoup that i will be working on...\n",
    "print (soup.title)\n",
    "print (soup.get_text())\n",
    "find_all()\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    print (link.get('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbc99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90bdbe",
   "metadata": {},
   "source": [
    "# turn the webpage into the data using BeautifulSoup to get the text!\n",
    "\n",
    "#  In this exercise, you'll figure out how to extract the text from the BDFL's webpage, along with printing the webpage's title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9873ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc17db",
   "metadata": {},
   "source": [
    "# Turning a webpage into data using BeautifulSoup: getting the hyperlinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbf95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "images/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "Resume.html\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags= soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print (link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac2432",
   "metadata": {},
   "source": [
    "# Introduction to APIs (application programming interface) \n",
    "        Used for building and interacting with software applications\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "# and JSONs (javascript object notation) \n",
    "    Keys in JSON will always be strings enclosed by quotation makes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc20837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading JSONs in Python\n",
    "import json\n",
    "with open ('snakes.json', \"r\") as json_file:\n",
    "    json_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in json_data.items():\n",
    "    print (key + ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c6fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_type(*args):\n",
    "    return type(args)\n",
    "\n",
    "check_type(1, 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3958d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of a is 10\n",
      "The value of b is 12\n",
      "The value of c is 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def easy_print(**x):                             # didnot get this code!\n",
    "        for key, value in x.items():\n",
    "            print('The value of ' + \n",
    "                  str(key) + \" is \" + \n",
    "                  str(value))\n",
    "(easy_print(a = 10), easy_print(b = 12), easy_print (c = 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle(length, width):\n",
    "    \"\"\"Returns the area and \n",
    "    perimeter of a rectangle\"\"\"\n",
    "    a = length * width\n",
    "    p = 2 * (length + width)\n",
    "    return a, p\n",
    "area, perimeter = rectangle(20, 5)\n",
    "print((area, perimeter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choice(c):\n",
    "    \"\"\"Returns the number associated \n",
    "       with your choice\"\"\"\n",
    "    choices = {'A': 25, 'B': 15, 'C': 50}\n",
    "    if c not in choices.keys():\n",
    "        raise 'Invalid Choice'\n",
    "    n = choices[c]\n",
    "    return n\n",
    "print (type(get_choice()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros(string):\n",
    "    \"\"\"Returns a string padded with zeros\n",
    "       to ensure consistent length\"\"\"\n",
    "    updated_string = string + '0'\n",
    "    def add_more():\n",
    "        \"\"\"Adds more zeros if necessary\"\"\"\n",
    "        nonlocal updated_string\n",
    "        updated_string = updated_string + '0'\n",
    "    \n",
    "    while len(updated_string) < 6:\n",
    "        add_more()\n",
    "    return \n",
    "(add_zeros('3.4'), add_zeros('8.678'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e90902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sat': 3, 'fri': 2}\n"
     ]
    }
   ],
   "source": [
    "x = ['sat', 'fri', 'fri', 'sat', 'sat']\n",
    "counts = {}\n",
    "for val in x:\n",
    "        if val in counts.keys():\n",
    "            counts[val] += 1\n",
    "        else:\n",
    "            counts[val] = 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82955a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_elements(x, desc=True, n=2):\n",
    "    new_x = sorted(x, reverse=desc)[0:n]\n",
    "    return new_x\n",
    "\n",
    "a= [8, 1, 4, 1, 4, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5116545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_arr1 = np.array([1,2,3,4])\n",
    "np_arr2 = np.array([5,6,7,8])\n",
    "print(np.column_stack((np_arr1, np_arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71458e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url= 'http://www.omdbapi.com/?apikey=72bc447a&t=the+social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Print the text of the response\n",
    "print (r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=the+social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Print the text of the response\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9b10d",
   "metadata": {},
   "source": [
    "\n",
    "# JSON-from the web to Python\n",
    "# In this step we are going to decode a JSON to store the result in the form of a dictionary\n",
    "\n",
    "# following code has made the json data much more presentable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cca52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r= requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data= r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3958d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url ='https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09010c3d",
   "metadata": {},
   "source": [
    "# Learning outcomes\n",
    "\n",
    "# Stream data from twitter API\n",
    "# filter incoming tweets for keywords\n",
    "# About API Authentification and OAuth\n",
    "\n",
    "# using Tweepy to look at the tweets online\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4782e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API authentication \n",
    "\n",
    "# Import package\n",
    "import tweepy\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steeming tweets\n",
    "\n",
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff0a5a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHURAN~1\\AppData\\Local\\Temp/ipykernel_17252/2496898225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Open connection to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtweets_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Read in tweets and store in list: tweets_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets.txt'"
     ]
    }
   ],
   "source": [
    "# Load and explore your Twitter data \n",
    "\n",
    "# Import package\n",
    "import json\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = 'tweets.txt'\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data= []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc040ef5",
   "metadata": {},
   "source": [
    "# Twitter data to DataFrame\n",
    "\n",
    "# we are going to extract the text and language of each tweet. \n",
    "\n",
    "\n",
    "API key = 'ILTwv349G0uL8ZimGZC2gZxxx'\n",
    "\n",
    "APU key Secret = '1aDfLDeXvZFsXXWegR1UkvaGykdckHuezxMduQnNTwggMe7otW'\n",
    "\n",
    "Bearer token = 'AAAAAAAAAAAAAAAAAAAAAK0HaAEAAAAANwddzEFifp1xuGb2Mr52yEINPao%3D7ONQKjln6CUteVMSKniRvbp5uSQ62f4N2O3zfGogI5JbcCEOMk'\n",
    "\n",
    "\n",
    "\n",
    "    If you want to access all public statistics, we need to go with 'Firehose' API which is paid. \n",
    "    \n",
    "    \n",
    "    Tweets are returned to as JASON's and they contain numerous possible features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ba59d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHURAN~1\\AppData\\Local\\Temp/ipykernel_39620/1275501004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maccess_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'AAAAAAAAAAAAAAAAAAAAAK0HaAEAAAAANwddzEFifp1xuGb2Mr52yEINPao%3D7ONQKjln6CUteVMSKniRvbp5uSQ62f4N2O3zfGogI5JbcCEOMk'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccess_token_secret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1aDfLDeXvZFsXXWegR1UkvaGykdckHuezxMduQnNTwggMe7otW'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ILTwv349G0uL8ZimGZC2gZxxx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy, json\n",
    "access_token = 'AAAAAAAAAAAAAAAAAAAAAK0HaAEAAAAANwddzEFifp1xuGb2Mr52yEINPao%3D7ONQKjln6CUteVMSKniRvbp5uSQ62f4N2O3zfGogI5JbcCEOMk'\n",
    "access_token_secret = '1aDfLDeXvZFsXXWegR1UkvaGykdckHuezxMduQnNTwggMe7otW'\n",
    "api_key = 'ILTwv349G0uL8ZimGZC2gZxxx'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3322e1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mystreamlistener' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHURAN~1\\AppData\\Local\\Temp/ipykernel_39620/4291897402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMystreamlistener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# this line filters twitter streams to capture data by keywords:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'apples'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'oranges'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Mystreamlistener' is not defined"
     ]
    }
   ],
   "source": [
    "l = Mystreamlistener()\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# this line filters twitter streams to capture data by keywords:\n",
    "stream.filter(track=['apples', 'oranges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88da93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns= ['text', 'lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000997a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of tweets containing the words- 'clinton', 'trump', 'sanders', 'cruz'\n",
    "\n",
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search (word, text)\n",
    "    \n",
    "    if match :\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca7d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khurana_Kunal\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD7CAYAAABE+8LhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYDklEQVR4nO3de3CNd+LH8c9JQlwyQ8SJW5fprLK76Oq66zaGLhEkkawdLRJmbRbLsDs26zqWlV+jGFqXWtSyNap0hcg00iy7Otu62860ptJi9kJwcreSICc5398f6lTE5fhKTqj3a6Yznuf7nPN8n/Qc7/M8TxIOY4wRAAAPKaC+JwAAeDIREACAFQICALBCQAAAVggIAMAKAQEAWCEgAAArQfU9AX8rLi6Tx8OPvgDAgwQEOBQa2vSe409dQDweQ0AAoBZwCQsAYIWAAACsEBAAgBUCAgCwQkAAAFYICADACgEBAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALBCQAAAVggIAMAKAQEAWKmXgGRkZGjYsGEaMmSItm3bVmP89OnTio+PV2RkpObNm6fKyspq41988YW6du3qr+kCAO7C7wFxuVxauXKl3n33Xe3Zs0c7duzQ2bNnq22TnJysBQsW6MMPP5QxRjt37vSOXbt2TYsXL5bb7fb31AEAt/F7QA4dOqS+ffuqefPmatKkiSIjI5WVleUdz83N1fXr19W9e3dJUnx8fLXxJUuWaPz48f6eNgDgDkH+3mFeXp6cTqd3OTw8XJ999tk9x51Op1wulyTpwIEDun79uoYOHWq9/7CwEOvHAgC+4feAeDweORwO77Ixptryvcbz8/O1bt06bdmy5ZH2X1hYKo/HPNJzAMDTICDAcd8P3X6/hNW6dWvl5+d7l/Pz8xUeHn7P8YKCAoWHh+vgwYMqKSnR2LFjFRsbK0mKjY1VaWmp/yYPAPDye0D69++vw4cPq6ioSNeuXVN2drYiIiK84+3atVNwcLBOnjwpSUpPT1dERIR+9rOfaf/+/UpPT1d6erp3LCSES1IAUB/8HpBWrVrpN7/5jRITEzVy5EiNGDFCzz//vJKSkvT5559LkpYvX67U1FQNHTpU5eXlSkxM9Pc0AQAP4DDGPFU3BLgHAgC+eezugQAAvh0ICADACgEBAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALBCQAAAVggIAMAKAQEAWCEgAAArBAQAYIWAAACsEBAAgBUCAgCwQkAAAFYICADACgEBAFghIAAAKwQEAGCFgAAArNRLQDIyMjRs2DANGTJE27ZtqzF++vRpxcfHKzIyUvPmzVNlZaUk6eTJkxo1apRiY2M1fvx45ebm+nvqAICv+T0gLpdLK1eu1Lvvvqs9e/Zox44dOnv2bLVtkpOTtWDBAn344Ycyxmjnzp3e9SkpKUpPT1d0dLRSUlL8PX0AwNf8HpBDhw6pb9++at68uZo0aaLIyEhlZWV5x3Nzc3X9+nV1795dkhQfH6+srCxVVFRoxowZ+t73vidJ6ty5sy5duuTv6QMAvub3gOTl5cnpdHqXw8PD5XK57jnudDrlcrnUsGFDxcbGSpI8Ho/WrFmjn/zkJ/6bOACgmiB/79Dj8cjhcHiXjTHVlh80XlFRodmzZ6uyslKTJk166P2HhYVYzhwAcDu/B6R169Y6ceKEdzk/P1/h4eHVxvPz873LBQUF3vGysjJNmTJFzZs317p169SgQYOH3n9hYak8HvMIRwAAT4eAAMd9P3T7/RJW//79dfjwYRUVFenatWvKzs5WRESEd7xdu3YKDg7WyZMnJUnp6ene8eTkZHXo0EFvvPGGGjZs6O+pAwBu4zDG+P3jeEZGhtavXy+3261Ro0YpKSlJSUlJmj59urp166acnBzNnz9fpaWl6tKli1JTU3X27FnFxcWpY8eOCgq6eeIUHh6ujRs3PtS+OQMBAN886AykXgJSnwgIAPjmsbuEBQD4diAgAAArBAQAYIWAAACsEBAAgBUCAgCwQkAAAFYICADACgEBAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALDiU0BcLleNdWfPnq31yQAAnhz3DUhJSYlKSkqUlJSkK1eueJcLCgo0bdo0f80RAPAYCrrf4MyZM/XJJ59Ikvr06fPNg4KCFBkZWbczAwA81hzGGPOgjebMmaPU1FR/zKfOFRaWyuN54CEDwFMvIMChsLCQe477FBBJys3N1ZUrV3T75l26dHn0GfoZAQEA3zwoIPe9hHXLqlWrtGnTJoWFhXnXORwOHThw4NFnCAB4IvkUkD179ig7O1utWrWq6/kAAJ4QPn0bb5s2bYgHAKAan+6BrFmzRuXl5Xr55ZfVqFEj73rugQDAt1et3EQfNGhQzQc+wj2QjIwMrVu3TpWVlRo/frzGjh1bbfz06dOaN2+eysrK1LNnTy1atEhBQUG6ePGikpOTVVhYqGeffVbLly9X06ZNH2rfBAQAfFNr34VVW1wul1599VWlpaWpYcOGeuWVV7RixQp17NjRu82IESOUkpKi7t27a+7cueratavGjBmjSZMmKSYmRsOHD9fatWtVXl6u5OTkh9o/AQEA3zwoID7dA9m8efNd/7Nx6NAh9e3bV82bN1eTJk0UGRmprKws73hubq6uX7+u7t27S5Li4+OVlZUlt9ut48ePe3+A8dZ6AED98Om7sL766ivvnysqKnT8+HH169fPaod5eXlyOp3e5fDwcH322Wf3HHc6nXK5XCouLlZISIiCgoKqrQcA1A+fAnLnT6G7XC7NmzfPaocej0cOh8O7bIyptnyv8Tu3k1Rj2Rf3Ox0DAPjOp4DcqVWrVsrNzbXaYevWrXXixAnvcn5+vsLDw6uN5+fne5cLCgoUHh6uFi1a6OrVq6qqqlJgYGCNx/mKeyAA4Jta+Un02+93GGN06tSpaj+V/jD69++v1atXq6ioSI0bN1Z2drYWL17sHW/Xrp2Cg4N18uRJ9ejRQ+np6YqIiFCDBg3Us2dPZWZmKjo6Wnv27FFERITVHAAAj87nX6Z4uxYtWighIUGtW7e22mlGRobWr18vt9utUaNGKSkpSUlJSZo+fbq6deumnJwczZ8/X6WlperSpYtSU1PVsGFD5ebmavbs2SosLFSbNm20YsUKNWvW7KH2zRkIAPimVr+NNzc3V5WVlerQoUOtTK4+EBAA8E2tXML6z3/+o1/96lfKy8uTx+NRaGio1q9fr+9+97u1NlEAwJPFpzOQiRMnasSIEYqLi5Mk7dq1S+np6XrnnXfqfIK1jTMQAPBNrfwgYWFhoTcekvTTn/5UxcXFjz47AMATy6eAVFVVqaSkxLtcVFRUV/MBADwhfLoHMm7cOI0ePVpRUVFyOBzKzMzU+PHj63puAIDHmE9nIAMGDJAkud1unTt3Ti6XS4MHD67TiQEAHm8+3USfMGGCBg0apMTERN24cUPbt2/XJ598oo0bN/pjjrWKm+gA4JtauYleXFysxMRESVJwcLAmTJhQ7deNAACePj7fRL/9N98WFBTIz/+MCADgMePTTfQJEyZo5MiReumll+RwOHTo0CH97ne/q+u5AQAeYz7/KpOcnBwdOXJEgYGB6tOnjzp16lTXc6sT3AMBAN88dv+kbX0jIADgm1q5iQ4AwJ0ICADACgEBAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALBCQAAAVggIAMCK3wNy8eJFjR07VkOHDtWUKVNUVlZWY5uKigolJycrKipKcXFxOnfunCSprKxMM2bMUHR0tKKjo/XBBx/4e/oAgK/5PSCLFi3SmDFjlJWVpa5du+qtt96qsc3WrVvVuHFj7du3T3PnztWcOXMkSRs2bFDbtm2VkZGhLVu2KDU1VQUFBf4+BACA/BwQt9ut48ePKzIyUpIUHx+vrKysGtsdPHhQMTExkqRevXqpqKhIFy9eVO/evZWQkCBJCgsLU/PmzQkIANSTIH/urLi4WCEhIQoKurlbp9Mpl8tVY7u8vDw5nU7vstPp1OXLl/Xiiy9612VmZqqiokIdO3as+4kDAGqos4Ds27dPqamp1dZ16NBBDoej2ro7lyXJGFNtvTFGAQHfnCzt27dPr732mt5++21vjHwVFhbyUNsDAO6uzgISFRWlqKioauvcbrf69OmjqqoqBQYGKj8/X+Hh4TUe26pVK+Xl5al9+/aSpIKCAu92W7du1aZNm7Rp0yZ17tz5oedVWFgqj8dYHBEAPF0CAhz3/dDt13sgDRo0UM+ePZWZmSlJ2rNnjyIiImpsN2DAAKWnp0uSTpw4oeDgYLVt21b79+/Xli1btH37dqt4AABqj8MY49eP47m5uZo9e7YKCwvVpk0brVixQs2aNdP27duVl5enGTNm6MaNG1qwYIFOnTqlhg0bKiUlRV26dFFMTIyKiooUFhbmfb6UlBR169bN5/1zBgIAvnnQGYjfA1LfCAgA+OaxuoQFAPj2ICAAACsEBABghYAAAKwQEACAFQICALBCQAAAVggIAMAKAQEAWCEgAAArBAQAYIWAAACsEBAAgBUCAgCwQkAAAFYICADACgEBAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALBCQAAAVvwekIsXL2rs2LEaOnSopkyZorKyshrbVFRUKDk5WVFRUYqLi9O5c+eqjVdWVmr06NFKS0vz17QBAHfwe0AWLVqkMWPGKCsrS127dtVbb71VY5utW7eqcePG2rdvn+bOnas5c+ZUG1+7dq3+/e9/+2nGAIC78WtA3G63jh8/rsjISElSfHy8srKyamx38OBBxcTESJJ69eqloqIiXbx4UZL0z3/+Uzk5ORo4cKD/Jg4AqMGvASkuLlZISIiCgoIkSU6nUy6Xq8Z2eXl5cjqd3mWn06nLly+rtLRUqampWrx4sd/mDAC4u6C6euJ9+/YpNTW12roOHTrI4XBUW3fnsiQZY6qtN8YoICBAixYt0qRJk9SyZUvreYWFhVg/FgDwjToLSFRUlKKioqqtc7vd6tOnj6qqqhQYGKj8/HyFh4fXeGyrVq2Ul5en9u3bS5IKCgrkdDp1+PBhffXVV1q9erUuXbqkI0eOKCgoyHu5yxeFhaXyeMyjHRwAPAUCAhz3/dBdZwG5mwYNGqhnz57KzMxUdHS09uzZo4iIiBrbDRgwQOnp6erZs6dOnDih4OBgtWvXTh9//LF3m9mzZ6t3794PFQ8AQO3x+3dh/f73v9fOnTs1bNgwnThxQr/+9a8lSdu3b9ebb74pSUpISFBFRYWGDx+u//u//9PSpUv9PU0AwAM4jDFP1fUcLmEBgG8edAmLn0QHAFghIAAAKwQEAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYAAAKwQEACAFQICALBCQAAAVggIAMAKAQEAWCEgAAArBAQAYIWAAACsEBAAgBUCAgCwQkAAAFaC6nsC/hYQ4KjvKQDAE+FBf186jDHGT3MBAHyLcAkLAGCFgAAArBAQAIAVAgIAsEJAAABWCAgAwAoBAQBYISAAACsEBABghYD4SUJCgo4eParPP/9c8+bNu++2f//737V582Y/zezJcPXqVU2dOrW+p4Gvde7cub6ngMfAU/e7sOpbt27d1K1bt/tuc+rUKT/N5slx5coVnT59ur6nAeA2BKQOGGO0fPly7d+/X4GBgRo9erR37OjRo1qzZo22bt2qhIQEdevWTSdPnlRRUZHmz5+vdu3a6b333pMktW3bVsOGDdP8+fP15ZdfyuFwaOLEiRo5cqTS0tL0j3/8Q1euXNH58+f14osvauHChfV0xHUvJSVFeXl5mjp1qs6dO6fQ0FA1atRI0dHROnbsmJYsWSLp5pnetGnTJEl//OMf1aBBA124cEGDBg1SkyZNtH//fknShg0b1LJlS/Xr10+DBw/Wp59+qqZNm2r58uV65pln6u0468Lly5f129/+VuXl5QoICND8+fN16dIlbd68WdevX1dFRYVee+01/ehHP7rra3LAgAG6cOGCkpOTVV5erh/+8Ife5y4rK9Mf/vAHnTlzRlVVVUpKStKIESOUlpam3bt3q6SkRAMHDtRzzz2nt99+W4GBgXrmmWe0bNkyBQcH1+NXpe7c7f2/f/9+NWvWTGfOnNEbb7yhkSNH6ssvv5QkpaWl6dixY5o2bVq1s+x//etfmjFjhiZOnFhfh/JgBrUuMzPTvPLKK+bGjRumtLTUxMTEmMjISHPkyBFz5MgRM27cOGOMMePGjTMpKSnGGGMOHDhg4uLijDHGrFq1yqxatcoYY8zrr79uFi9ebIwxprCw0AwaNMicPn3a7Nq1ywwYMMBcvXrVlJeXm4iICJOTk1MPR+sf58+fNwMHDjTnz583nTp1MufPnzfGGLNr1y4za9Ys73bjxo3zfp1feOEFc/HiRVNeXm66d+9utm/fbowxZvbs2WbLli3GGGM6depk0tLSjDHGvPPOO2bSpEl+PrK6t3r1arNx40ZjjDEfffSR2bBhg0lMTDSFhYXGGGPef/9973Hf6zX5y1/+0uzcudMYY8zu3btNp06djDHGLFu2zPz5z382xhhz9epVM3z4cPPf//7X7Nq1ywwePNi43W5jjDGDBg0yBQUFxhhjlixZYr744gt/HHq9uNf7/9Z72hjj/foZU/M1bIwx2dnZJj4+3ly/ft1v87bBPZA6cPz4cUVFRalhw4Zq2rSp0tPT5XQ677rtSy+9JEl67rnnVFJSUmP8yJEjGjVqlCSpRYsWevnll3Xs2DFJ0gsvvKCQkBA1btxY3/nOd3TlypW6OaDHTFhYmE9nCZ06dVKbNm3UuHFjhYaGql+/fpJuntn973//kyQFBwdr5MiRkqS4uDgdPXq0zuZdX/r166c//elPmjlzpkpKSpSYmKi1a9fq448/1ptvvqndu3errKzMu/3dXpPHjh1TVFSUJCkmJkYNGjSQJB06dEjvvfeeYmNjNXbsWJWXl+vMmTOSpB/84AcKCrp5kWPgwIF69dVXtXTpUkVGRur73/++vw7f7+71/n/++ed9enxOTo6WLFmi1atXP/ZnaVzCqgNBQUFyOL75PfoXLlxQeXn5Xbe99QK5ffvbmTt+274xRlVVVdUee+vxd277bdWoUSPvn+88brfb7f3zrb/kbgkMDKzxXAEBAd6vvcfjues2T7oePXrogw8+0MGDB5WZman3339f+fn5iomJUa9evdS5c2dt27bNu/29XpO3vs4Oh0MBATc/e3o8Hi1btkxdunSRJBUUFKhZs2bKyMio9v9p/vz5ysnJ0UcffaTk5GRNmzZNsbGxdXrc9eVe7//bvx7Sza+nw+FQZWWld11RUZGmT5+u1157TW3btvXbnG1xBlIHevXqpezsbLndbl27dk2/+MUv5HK5fH58YGCg90XVt29f/eUvf5F088V14MAB9e7du07m/TgLCgqq9ka7JTQ0VOfOnZMxRufPn/deV/bVtWvX9Le//U3SzWvRERERtTLfx8nSpUu1d+9excXFacGCBTp27JgcDocmT56sPn366K9//av3Q8m99O/fX3v37pUkZWdn68aNG5Juvj63b98uScrLy1NMTIwuXbpU7bGVlZUaMmSIQkNDNWnSJMXGxn6rvyHCl/d/aGiozpw5I2OM9/Xndrs1Y8YMJSQkqE+fPvUx9YfGGUgdGDx4sE6dOqX4+Hh5PB4lJiZq3759Pj++V69emjVrllq2bKmpU6dq4cKFio6OVlVVlSZPnqwuXbo89F+UT7qwsDC1bdtWc+bMqba+f//+2rVrl4YOHapnn31WPXr0eOjnzsrK0sqVKxUeHq7XX3+9tqb82EhISNDMmTOVlpamwMBArV+/Xnv37lVUVJQcDod+/OMf6+TJk/d9jgULFig5OVk7duxQ165d1bRpU0nStGnTtHDhQo0YMUJVVVVKTk5W+/btdeLECe9jg4KCNH36dP385z9XcHCwwsLCvN/08G3ky/t/5syZmjx5slq2bKkePXqouLhYWVlZ+vTTT3Xt2jXt2rVLxhj1799fs2bNqqcjeTD+RUI81Tp37vzUxRioLVzCAgBY4QwEAGCFMxAAgBUCAgCwQkAAAFYICADACgEBAFghIAAAK/8PszMrPoJRhQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the twitter data with seaborn\n",
    "\n",
    "# there was no data loaded, so is the reason that the plot is emplty\n",
    "\n",
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = sns.barplot(cd, [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf8b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
