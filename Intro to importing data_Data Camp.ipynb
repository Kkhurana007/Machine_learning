{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e108d32",
   "metadata": {},
   "source": [
    "# Print files to console\n",
    "# Print specfic lines\n",
    "# Discuss flat files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39ed39",
   "metadata": {},
   "source": [
    "# Reading a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fa622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'abc'                   # opening a flat file\n",
    "file = open(filename, mode= 'r')   # mode 'r' is used to read; we won't be able to read the file\n",
    "text = file.read()\n",
    "file.close()                        # always be clean while cooking\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f3acd",
   "metadata": {},
   "source": [
    "# Writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc3580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'abc'\n",
    "file = open (filename, mode = 'w')\n",
    "text = file.read()\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5da826",
   "metadata": {},
   "source": [
    "# Context manager with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff2002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('abc.txt', 'r') as file:\n",
    "    print (file.read())                        #no need to close the file with 'with statement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee40c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2b746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing exercise\n",
    "\n",
    "\n",
    "# Open a file: file\n",
    "file = open('CV_Kunal.txt', mode = 'r')\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n",
    "\n",
    "# Check whether file is closed\n",
    "print (file.closed)\n",
    "\n",
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print (file.closed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534d75b",
   "metadata": {},
   "source": [
    "# Reading files line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed48280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read & print the first 3 lines\n",
    "with open('moby_dick.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d0d83d",
   "metadata": {},
   "source": [
    "# NumPy and Pandas are used to import numerical data\n",
    "\n",
    "\n",
    "# Flat files with only numerical called MNIST  -- Case 1\n",
    "\n",
    "\n",
    "\n",
    "# Flat files numerical data and strings (titanic.csv) - Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a7b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no idea about this\n",
    "\n",
    "import imp\n",
    "imp.reload(this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73376997",
   "metadata": {},
   "source": [
    "# Why importing *flat files* using NumPy?\n",
    "    Because it is essential for other packages e.g.-scikit learn\n",
    "    \n",
    "    Morevoer, it has some built in funcitons that help us to load the files from within--like-----\n",
    "    1) loadtxt()\n",
    "    2) genfromtxt()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea89e93",
   "metadata": {},
   "source": [
    "# Customising NumPy import \n",
    "\n",
    "    import numpy as np\n",
    "filename = 'abc'\n",
    "data = np.loadtxt(filename, delimiter = ',', skiprows= 1, usecols = [0,2], dtype = str) \n",
    "print (data)\n",
    "\n",
    "    meaning of all this-\n",
    "    1) usecols - selects the selected number of colomns\n",
    "    2) skiprows - skips the rows or headers that are there in the text\n",
    "    3) deliminter - used for spacing and adding comas in the files.\n",
    "    4) dtye = str (this will ensure that all the data types are improted as strings\n",
    "    \n",
    " [Remark- Although NumPy can handle such data types, but the natural place for this data types is DataFrames.]\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332d187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how to get the file directly from the directory\n",
    "\n",
    "\n",
    "with open('gender_submission_desktop.csv', 'r') as file:\n",
    "    print (file.read())  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d2e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import numpy as np\n",
    "\n",
    "# Assign filename to variable: file\n",
    "file = 'gender_submission_desktop.csv'\n",
    "\n",
    "\n",
    "    \n",
    "# Load file as array: digits\n",
    "digits = np.loadtxt(file, delimiter=',')\n",
    "\n",
    "# Print datatype of digits\n",
    "print(digits)\n",
    "\n",
    "# Select and reshape a row\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))\n",
    "\n",
    "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d209639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    "\n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt(file, delimiter='\\t', dtype=float, skiprows=1)\n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(data_float[9])\n",
    "\n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78fcb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remark - np.genfromtxt() imports the data from mixed data types too. \n",
    "\n",
    "\n",
    "# importing data file quickly \n",
    "\n",
    "\n",
    "data = np.genfromtxt('titanic.csv', delimiter = ',', names = True, dtype=None)\n",
    "\n",
    "#printing specific colomn\n",
    "\n",
    "data ['Specific_colomn_name']\n",
    "\n",
    "# example stating this\n",
    "\n",
    "\n",
    "# Import file using np.recfromcsv: d\n",
    "d = np.recfromcsv('titanic.csv', delimiter= ',', names = True, dtype= None)\n",
    "\n",
    "# Print out first three entries of d\n",
    "print(d[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193d897",
   "metadata": {},
   "source": [
    "# Why manipulating DataFrames in pandas is important?\n",
    "\n",
    "## Exploratory data analysis\n",
    "## Data wrangling\n",
    "## Data preprocessing\n",
    "## Building models\n",
    "## Visualization\n",
    "\n",
    "    Pandas is used for flat files management in data science or data management. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = 'gender_submission_desktop'\n",
    "data = pd.read_csv(filename)\n",
    "data.head()      # to check first 5 rows of the DataFrame including the header\n",
    "data_array = data.values   # convering the data to a NumPy arrays by calling the data attributes values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of importing data files as DataFrames\n",
    "\n",
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'titanic.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "print (df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the filename: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Read the first 5 rows of the file into a DataFrame: data\n",
    "data = pd.read_csv(file, nrows= 5, header = None)\n",
    "\n",
    "\n",
    "# Build a numpy array from the DataFrame: data_array\n",
    "data_array = data.values\n",
    "\n",
    "# Print the datatype of data_array to the shell\n",
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f60133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0994e",
   "metadata": {},
   "source": [
    "# Data Scientists mostly used pandas to import the data files\n",
    "# Use of pandas for importing SAS, Excel, MATLAB, HDF5 and Stata\n",
    "\n",
    "  # Pickled (serialized) files ; Serialized= convert object to bytestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f54e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickled files \n",
    "\n",
    "import pickle\n",
    "with open ('pickled_fruit.pkl', 'rb') as file:      #rb= readable and binary (computer readable only)\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data)\n",
    "\n",
    "\n",
    "# importing Excel spredsheets\n",
    "\n",
    "import pandas as pd\n",
    "file = 'urbanpop.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "print (data.sheet_names)      #this will give sheet names\n",
    "\n",
    "# two ways of importing data (as strings, or as a float with index number)\n",
    "\n",
    "df1 = data.parse('abc')     #sheet name, as a string\n",
    "df2 = data.parse(0)         #sheet name, as a float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018443c",
   "metadata": {},
   "source": [
    "# More into this---\n",
    "   ## customize the import (skip rows, import certain colomns, change colomn names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958adc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wd = os.getcwd()   #stoes the name of current directory in a string\n",
    "os.listdir(wd)      # outputs the contents of the directory in list format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd2b6f",
   "metadata": {},
   "source": [
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xls.parse('2004')\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Load a sheet into a DataFrame by index: df2\n",
    "df2 = xls.parse(1)\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "    print(df2.head())         #mistake here, i didnot add the brackets after head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xls.parse(0, skiprows=[0], names=['Country', 'AAM due to War(2002)'])\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xls.parse(1, usecols=[1], skiprows=[1], names=['Country'])            #missed square brackets \n",
    "                                                                            # index number starts from 0\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33af0f",
   "metadata": {},
   "source": [
    "# 1. SAS (common in buisness analytics and biostatistics) and \n",
    "# 2. Stata files (academic social sciences res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "with SAS7DAT('abc.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "    \n",
    "# case 2\n",
    "data = pd.read_stata(abc.dta)     # no need to initialize context manager in this case\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2698bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print (df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df = pd.read_stata('disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print (df.head())\n",
    "\n",
    "# Plot histogram of one column of the DataFrame\n",
    "pd.DataFrame.hist(df[['disa10']])           #question- why double squrare brackets here?\n",
    "plt.xlabel('Extent of disease')\n",
    "plt.ylabel('Number of countries')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9284b6",
   "metadata": {},
   "source": [
    "# Importing HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ff3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "filename = 'abc.hdf5'\n",
    "data =  h5py.File (filename, 'r')   # 'r' is to read \n",
    "print (type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec927d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys():\n",
    "    print (key)\n",
    "    \n",
    "# response - meta, quality, strain\n",
    "\n",
    "# find out the type of meta data \n",
    "\n",
    "for key in data ['meta'].keys():\n",
    "    print (key)\n",
    "\n",
    "    \n",
    "# for description of data and detection\n",
    "print (data['meta']['Description'].value. data['meta']['Detector'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'LIGO_data.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "print (type(data))\n",
    "\n",
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2158bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice excersice\n",
    "\n",
    "# Get the HDF5 group: group\n",
    "group = data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain = data['strain']['Strain'].value\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "num_samples = 10000\n",
    "\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(time, strain[:num_samples])\n",
    "plt.xlabel('GPS Time (s)')\n",
    "plt.ylabel('strain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dd8e4",
   "metadata": {},
   "source": [
    "# Importing MATLAB files (Matrix laboratory)\n",
    "# SciPy's loadmat() and savemat() can be used to access these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f2446",
   "metadata": {},
   "source": [
    "# Import package\n",
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat = scipy.io.loadmat('albeck_gene_expression.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the keys of the MATLAB dictionary\n",
    "print(mat.keys())\n",
    "\n",
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print (type(mat['CYratioCyt']))\n",
    "\n",
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "np.shape('CYratioCyt')\n",
    "\n",
    "\n",
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(data)\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('normalized fluorescence (measure of expression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4eb49",
   "metadata": {},
   "source": [
    "# Introduction to relational databases in Python\n",
    "\n",
    "## each row = order\n",
    "## each column = attribute\n",
    "\n",
    "### tables are linked\n",
    "### Relational database management systems (postgreSQL, MySQL, SQLite)\n",
    "\n",
    "### Creating a database engine in Python using SQL\n",
    "\n",
    "### package mosty used = SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine ('sqlite:///Northwind.sqlite')\n",
    "\n",
    "# getting table names-\n",
    "table_names = engine.table_names()\n",
    "print (table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise practice \n",
    "\n",
    "# Import necessary module\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine ('sqlite:///Chinook.sqlite')       (# got syntax error as i put 2 forward slashes instead of 3)\n",
    "\n",
    "# Save the table names to a list: table_names\n",
    "table_names = engine.table_names()\n",
    "\n",
    "# Print the table names to the shell\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f995427",
   "metadata": {},
   "source": [
    "# Querying relational databases in Python\n",
    "\n",
    "SELECT * FROM Table_name                 # hello world in SQL\n",
    "\n",
    "SELECT * FROM Orders\n",
    "\n",
    "# we'll use SQLAlchemy and pandas\n",
    "\n",
    "# Workflow (5 steps; Import packages and fns , database engine, connect, query, Save results to a DataFrame, Close the connection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine                #Step 1\n",
    "import pandas as pd\n",
    "engine = create_engine ('sqlite: ///Northwind.sqlite')    # Step 2\n",
    "con = engine.connect()                                     # Step 3\n",
    "rs = con.execute (\"SELECT * FROM Orders\")                   # Step 4\n",
    "df = pd.DataFrame (rs.fetchall())                             # Step 5\n",
    "con.close()                                                    # close finally\n",
    "\n",
    "\n",
    "print(df.head())             #repetition; print head\n",
    "# if the names of colomns doesn't look good, fix this by \n",
    "df.colomns = rs.keys()                 # add this before closing the file\n",
    "\n",
    "\n",
    "# using context manager as in first case:\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine ('sqlite:///Northwind.sqlite')\n",
    "\n",
    "\n",
    "with engine.connect() as  con:\n",
    "    rs = con.execute (\"SELECT OrderID, OrderData, ShipName FROM Orders\") #difference1 (instead of *, use selectivecolomn names)\n",
    "    df = pd.DataFrame(rs.fetchmany(size = 5))       #difference2 = fetchmany instead of fetchall\n",
    "    df.columns = rs.keys()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e9023",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine connection: con\n",
    "con = engine.connect()\n",
    "\n",
    "# Perform query: rs\n",
    "rs = con.execute('SELECT * from Album')\n",
    "\n",
    "# Save results of the query to DataFrame: df\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "# Close connection\n",
    "con.close()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute ('SELECT LastName, Title FROM Employee')\n",
    "    df = pd.DataFrame(rs.fetchmany (size = 3))\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the length of the DataFrame df\n",
    "print(len(df))\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e500c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5580d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT *  FROM Employee WHERE EmployeeId >=6')\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d6c04",
   "metadata": {},
   "source": [
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine in context manager\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute ('SELECT * from Employee ORDER by Birthdate')\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "    # Set the DataFrame's column names\n",
    "df.columns = rs.keys()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6404b",
   "metadata": {},
   "source": [
    "# Relational databases with pandas\n",
    "\n",
    "using sequel queries and using pandas to execute them.\n",
    "\n",
    "\n",
    "Same 4 liner code can be reduced to one line. \n",
    "        #(connecting, executing, passing the result to the DataFrame, finally, naming the columns)\n",
    "        \n",
    "Now with pandas function (read_sql_query) \n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM Orders', engine) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4686a3aa",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query('SELECT * FROM Album', engine)\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Open engine in context manager and store query result in df1\n",
    "with engine.connect() as con:\n",
    "    \n",
    "    rs = con.execute(\"SELECT * FROM Album\")\n",
    "    \n",
    "    df1 = pd.DataFrame(rs.fetchall())\n",
    "    \n",
    "    df1.columns = rs.keys()\n",
    "\n",
    "# Confirm that both methods yield the same result\n",
    "print(df.equals(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ae4d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffe151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query('SELECT * FROM Employee WHERE EmployeeId >=6 ORDER by BirthDate', engine)\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making use of Inner JOIN in Python (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76aff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT Title, Name FROM Album INNER JOIN Artist on Album.ArtistID = Artist.ArtistID')\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e035f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
